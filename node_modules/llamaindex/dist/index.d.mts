import OpenAI$1, { ClientOptions as ClientOptions$1 } from 'openai';
import Anthropic$1, { ClientOptions } from '@anthropic-ai/sdk';
import Replicate from 'replicate';
import { ParseConfig } from 'papaparse';

declare enum NodeRelationship {
    SOURCE = "SOURCE",
    PREVIOUS = "PREVIOUS",
    NEXT = "NEXT",
    PARENT = "PARENT",
    CHILD = "CHILD"
}
declare enum ObjectType {
    TEXT = "TEXT",
    IMAGE = "IMAGE",
    INDEX = "INDEX",
    DOCUMENT = "DOCUMENT"
}
declare enum MetadataMode {
    ALL = "ALL",
    EMBED = "EMBED",
    LLM = "LLM",
    NONE = "NONE"
}
interface RelatedNodeInfo {
    nodeId: string;
    nodeType?: ObjectType;
    metadata: Record<string, any>;
    hash?: string;
}
type RelatedNodeType = RelatedNodeInfo | RelatedNodeInfo[];
/**
 * Generic abstract class for retrievable nodes
 */
declare abstract class BaseNode {
    /**
     * The unique ID of the Node/Document. The trailing underscore is here
     * to avoid collisions with the id keyword in Python.
     *
     * Set to a UUID by default.
     */
    id_: string;
    embedding?: number[];
    metadata: Record<string, any>;
    excludedEmbedMetadataKeys: string[];
    excludedLlmMetadataKeys: string[];
    relationships: Partial<Record<NodeRelationship, RelatedNodeType>>;
    hash: string;
    constructor(init?: Partial<BaseNode>);
    abstract getType(): ObjectType;
    abstract getContent(metadataMode: MetadataMode): string;
    abstract getMetadataStr(metadataMode: MetadataMode): string;
    abstract setContent(value: any): void;
    get sourceNode(): RelatedNodeInfo | undefined;
    get prevNode(): RelatedNodeInfo | undefined;
    get nextNode(): RelatedNodeInfo | undefined;
    get parentNode(): RelatedNodeInfo | undefined;
    get childNodes(): RelatedNodeInfo[] | undefined;
    abstract generateHash(): string;
    getEmbedding(): number[];
    asRelatedNodeInfo(): RelatedNodeInfo;
    /**
     * Used with built in JSON.stringify
     * @returns
     */
    toJSON(): Record<string, any>;
}
/**
 * TextNode is the default node type for text. Most common node type in LlamaIndex.TS
 */
declare class TextNode extends BaseNode {
    text: string;
    startCharIdx?: number;
    endCharIdx?: number;
    metadataSeparator: string;
    constructor(init?: Partial<TextNode>);
    /**
     * Generate a hash of the text node.
     * The ID is not part of the hash as it can change independent of content.
     * @returns
     */
    generateHash(): string;
    getType(): ObjectType;
    getContent(metadataMode?: MetadataMode): string;
    getMetadataStr(metadataMode: MetadataMode): string;
    setContent(value: string): void;
    getNodeInfo(): {
        start: number | undefined;
        end: number | undefined;
    };
    getText(): string;
}
declare class IndexNode extends TextNode {
    indexId: string;
    constructor(init?: Partial<IndexNode>);
    getType(): ObjectType;
}
/**
 * A document is just a special text node with a docId.
 */
declare class Document extends TextNode {
    constructor(init?: Partial<Document>);
    getType(): ObjectType;
}
declare function jsonToNode(json: any): TextNode;
/**
 * A node with a similarity score
 */
interface NodeWithScore {
    node: BaseNode;
    score: number;
}

type EventTag = "intermediate" | "final";
type EventType = "retrieve" | "llmPredict" | "wrapper";
interface Event {
    id: string;
    type: EventType;
    tags?: EventTag[];
    parentId?: string;
}
interface BaseCallbackResponse {
    event: Event;
}
interface StreamToken {
    id: string;
    object: string;
    created: number;
    model: string;
    choices: {
        index: number;
        delta: {
            content?: string | null;
            role?: "user" | "assistant" | "system" | "function";
        };
        finish_reason: string | null;
    }[];
}
interface StreamCallbackResponse extends BaseCallbackResponse {
    index: number;
    isDone?: boolean;
    token?: StreamToken;
}
interface RetrievalCallbackResponse extends BaseCallbackResponse {
    query: string;
    nodes: NodeWithScore[];
}
interface CallbackManagerMethods {
    onLLMStream?: (params: StreamCallbackResponse) => Promise<void> | void;
    onRetrieve?: (params: RetrievalCallbackResponse) => Promise<void> | void;
}
declare class CallbackManager implements CallbackManagerMethods {
    onLLMStream?: (params: StreamCallbackResponse) => Promise<void> | void;
    onRetrieve?: (params: RetrievalCallbackResponse) => Promise<void> | void;
    constructor(handlers?: CallbackManagerMethods);
}

declare class AnthropicSession {
    anthropic: Anthropic$1;
    constructor(options?: ClientOptions);
}

interface AzureOpenAIConfig {
    apiKey?: string;
    endpoint?: string;
    apiVersion?: string;
    deploymentName?: string;
}

declare class OpenAISession {
    openai: OpenAI$1;
    constructor(options?: ClientOptions$1 & {
        azure?: boolean;
    });
}

declare class ReplicateSession {
    replicateKey: string | null;
    replicate: Replicate;
    constructor(replicateKey?: string | null);
}

type MessageType = "user" | "assistant" | "system" | "generic" | "function";
interface ChatMessage {
    content: string;
    role: MessageType;
}
interface ChatResponse {
    message: ChatMessage;
    raw?: Record<string, any>;
    delta?: string;
}
type CompletionResponse = ChatResponse;
/**
 * Unified language model interface
 */
interface LLM {
    /**
     * Get a chat response from the LLM
     * @param messages
     */
    chat(messages: ChatMessage[], parentEvent?: Event): Promise<ChatResponse>;
    /**
     * Get a prompt completion from the LLM
     * @param prompt the prompt to complete
     */
    complete(prompt: string, parentEvent?: Event): Promise<CompletionResponse>;
}
declare const GPT4_MODELS: {
    "gpt-4": {
        contextWindow: number;
    };
    "gpt-4-32k": {
        contextWindow: number;
    };
};
declare const TURBO_MODELS: {
    "gpt-3.5-turbo": {
        contextWindow: number;
    };
    "gpt-3.5-turbo-16k": {
        contextWindow: number;
    };
};
/**
 * We currently support GPT-3.5 and GPT-4 models
 */
declare const ALL_AVAILABLE_OPENAI_MODELS: {
    "gpt-3.5-turbo": {
        contextWindow: number;
    };
    "gpt-3.5-turbo-16k": {
        contextWindow: number;
    };
    "gpt-4": {
        contextWindow: number;
    };
    "gpt-4-32k": {
        contextWindow: number;
    };
};
/**
 * OpenAI LLM implementation
 */
declare class OpenAI implements LLM {
    model: keyof typeof ALL_AVAILABLE_OPENAI_MODELS;
    temperature: number;
    topP: number;
    maxTokens?: number;
    additionalChatOptions?: Omit<Partial<OpenAI$1.Chat.CompletionCreateParams>, "max_tokens" | "messages" | "model" | "temperature" | "top_p" | "streaming">;
    apiKey?: string;
    maxRetries: number;
    timeout?: number;
    session: OpenAISession;
    additionalSessionOptions?: Omit<Partial<ClientOptions$1>, "apiKey" | "maxRetries" | "timeout">;
    callbackManager?: CallbackManager;
    constructor(init?: Partial<OpenAI> & {
        azure?: AzureOpenAIConfig;
    });
    mapMessageType(messageType: MessageType): "user" | "assistant" | "system" | "function";
    chat(messages: ChatMessage[], parentEvent?: Event): Promise<ChatResponse>;
    complete(prompt: string, parentEvent?: Event): Promise<CompletionResponse>;
}
declare const ALL_AVAILABLE_LLAMADEUCE_MODELS: {
    "Llama-2-70b-chat-old": {
        contextWindow: number;
        replicateApi: string;
    };
    "Llama-2-70b-chat-4bit": {
        contextWindow: number;
        replicateApi: string;
    };
    "Llama-2-13b-chat": {
        contextWindow: number;
        replicateApi: string;
    };
    "Llama-2-13b-chat-4bit": {
        contextWindow: number;
        replicateApi: string;
    };
    "Llama-2-7b-chat": {
        contextWindow: number;
        replicateApi: string;
    };
    "Llama-2-7b-chat-4bit": {
        contextWindow: number;
        replicateApi: string;
    };
};
declare enum DeuceChatStrategy {
    A16Z = "a16z",
    META = "meta",
    METAWBOS = "metawbos",
    REPLICATE4BIT = "replicate4bit"
}
/**
 * Llama2 LLM implementation
 */
declare class LlamaDeuce implements LLM {
    model: keyof typeof ALL_AVAILABLE_LLAMADEUCE_MODELS;
    chatStrategy: DeuceChatStrategy;
    temperature: number;
    topP: number;
    maxTokens?: number;
    replicateSession: ReplicateSession;
    constructor(init?: Partial<LlamaDeuce>);
    mapMessagesToPrompt(messages: ChatMessage[]): {
        prompt: string;
        systemPrompt: string | undefined;
    };
    mapMessagesToPromptA16Z(messages: ChatMessage[]): {
        prompt: string;
        systemPrompt: undefined;
    };
    mapMessageTypeA16Z(messageType: MessageType): string;
    mapMessagesToPromptMeta(messages: ChatMessage[], opts?: {
        withBos?: boolean;
        replicate4Bit?: boolean;
    }): {
        prompt: string;
        systemPrompt: string | undefined;
    };
    chat(messages: ChatMessage[], _parentEvent?: Event): Promise<ChatResponse>;
    complete(prompt: string, parentEvent?: Event): Promise<CompletionResponse>;
}
/**
 * Anthropic LLM implementation
 */
declare class Anthropic implements LLM {
    model: string;
    temperature: number;
    topP: number;
    maxTokens?: number;
    apiKey?: string;
    maxRetries: number;
    timeout?: number;
    session: AnthropicSession;
    callbackManager?: CallbackManager;
    constructor(init?: Partial<Anthropic>);
    mapMessagesToPrompt(messages: ChatMessage[]): string;
    chat(messages: ChatMessage[], parentEvent?: Event | undefined): Promise<ChatResponse>;
    complete(prompt: string, parentEvent?: Event | undefined): Promise<CompletionResponse>;
}

/**
 * An OutputParser is used to extract structured data from the raw output of the LLM.
 */
interface BaseOutputParser<T> {
    parse(output: string): T;
    format(output: string): string;
}
/**
 * StructuredOutput is just a combo of the raw output and the parsed output.
 */
interface StructuredOutput<T> {
    rawOutput: string;
    parsedOutput: T;
}
/**
 * SubQuestionOutputParser is used to parse the output of the SubQuestionGenerator.
 */
declare class SubQuestionOutputParser implements BaseOutputParser<StructuredOutput<SubQuestion[]>> {
    parse(output: string): StructuredOutput<SubQuestion[]>;
    format(output: string): string;
}

interface SubQuestion {
    subQuestion: string;
    toolName: string;
}
/**
 * QuestionGenerators generate new questions for the LLM using tools and a user query.
 */
interface BaseQuestionGenerator {
    generate(tools: ToolMetadata[], query: string): Promise<SubQuestion[]>;
}
/**
 * LLMQuestionGenerator uses the LLM to generate new questions for the LLM using tools and a user query.
 */
declare class LLMQuestionGenerator implements BaseQuestionGenerator {
    llm: LLM;
    prompt: SimplePrompt;
    outputParser: BaseOutputParser<StructuredOutput<SubQuestion[]>>;
    constructor(init?: Partial<LLMQuestionGenerator>);
    generate(tools: ToolMetadata[], query: string): Promise<SubQuestion[]>;
}

/**
 * Respone is the output of a LLM
 */
declare class Response {
    response: string;
    sourceNodes?: BaseNode[];
    constructor(response: string, sourceNodes?: BaseNode[]);
    getFormattedSources(): void;
    toString(): string;
}

/**
 * A filesystem interface that is meant to be compatible with
 * the 'fs' module from Node.js.
 * Allows for the use of similar inteface implementation on
 * browsers.
 */
interface GenericFileSystem {
    writeFile(path: string, content: string, options?: any): Promise<void>;
    readFile(path: string, options?: any): Promise<string>;
    access(path: string): Promise<void>;
    mkdir(path: string, options?: any): Promise<void>;
}
interface WalkableFileSystem {
    readdir(path: string): Promise<string[]>;
    stat(path: string): Promise<any>;
}
/**
 * A filesystem implementation that stores files in memory.
 */
declare class InMemoryFileSystem implements GenericFileSystem {
    private files;
    writeFile(path: string, content: string, options?: any): Promise<void>;
    readFile(path: string, options?: any): Promise<string>;
    access(path: string): Promise<void>;
    mkdir(path: string, options?: any): Promise<void>;
}
type CompleteFileSystem = GenericFileSystem & WalkableFileSystem;
declare function getNodeFS(): CompleteFileSystem;
declare const DEFAULT_FS: GenericFileSystem | CompleteFileSystem;
/**
 * Checks if a file exists.
 * Analogous to the os.path.exists function from Python.
 * @param fs The filesystem to use.
 * @param path The path to the file to check.
 * @returns A promise that resolves to true if the file exists, false otherwise.
 */
declare function exists(fs: GenericFileSystem, path: string): Promise<boolean>;
/**
 * Recursively traverses a directory and yields all the paths to the files in it.
 * @param fs The filesystem to use.
 * @param dirPath The path to the directory to traverse.
 */
declare function walk(fs: WalkableFileSystem, dirPath: string): AsyncIterable<string>;

interface VectorStoreQueryResult {
    nodes?: BaseNode[];
    similarities: number[];
    ids: string[];
}
declare enum VectorStoreQueryMode {
    DEFAULT = "default",
    SPARSE = "sparse",
    HYBRID = "hybrid",
    SVM = "svm",
    LOGISTIC_REGRESSION = "logistic_regression",
    LINEAR_REGRESSION = "linear_regression",
    MMR = "mmr"
}
interface ExactMatchFilter {
    filterType: "ExactMatch";
    key: string;
    value: string | number;
}
interface MetadataFilters {
    filters: ExactMatchFilter[];
}
interface VectorStoreQuerySpec {
    query: string;
    filters: ExactMatchFilter[];
    topK?: number;
}
interface MetadataInfo {
    name: string;
    type: string;
    description: string;
}
interface VectorStoreInfo {
    metadataInfo: MetadataInfo[];
    contentInfo: string;
}
interface VectorStoreQuery {
    queryEmbedding?: number[];
    similarityTopK: number;
    docIds?: string[];
    queryStr?: string;
    mode: VectorStoreQueryMode;
    alpha?: number;
    filters?: MetadataFilters;
    mmrThreshold?: number;
}
interface VectorStore {
    storesText: boolean;
    isEmbeddingQuery?: boolean;
    client(): any;
    add(embeddingResults: BaseNode[]): Promise<string[]>;
    delete(refDocId: string, deleteKwargs?: any): Promise<void>;
    query(query: VectorStoreQuery, kwargs?: any): Promise<VectorStoreQueryResult>;
    persist(persistPath: string, fs?: GenericFileSystem): Promise<void>;
}

/**
 * Similarity type
 * Default is cosine similarity. Dot product and negative Euclidean distance are also supported.
 */
declare enum SimilarityType {
    DEFAULT = "cosine",
    DOT_PRODUCT = "dot_product",
    EUCLIDEAN = "euclidean"
}
/**
 * The similarity between two embeddings.
 * @param embedding1
 * @param embedding2
 * @param mode
 * @returns similartiy score with higher numbers meaning the two embeddings are more similar
 */
declare function similarity(embedding1: number[], embedding2: number[], mode?: SimilarityType): number;
/**
 * Get the top K embeddings from a list of embeddings ordered by similarity to the query.
 * @param queryEmbedding
 * @param embeddings list of embeddings to consider
 * @param similarityTopK max number of embeddings to return, default 2
 * @param embeddingIds ids of embeddings in the embeddings list
 * @param similarityCutoff minimum similarity score
 * @returns
 */
declare function getTopKEmbeddings(queryEmbedding: number[], embeddings: number[][], similarityTopK?: number, embeddingIds?: any[] | null, similarityCutoff?: number | null): [number[], any[]];
declare function getTopKEmbeddingsLearner(queryEmbedding: number[], embeddings: number[][], similarityTopK?: number, embeddingsIds?: any[], queryMode?: VectorStoreQueryMode): [number[], any[]];
declare function getTopKMMREmbeddings(queryEmbedding: number[], embeddings: number[][], similarityFn?: ((...args: any[]) => number) | null, similarityTopK?: number | null, embeddingIds?: any[] | null, _similarityCutoff?: number | null, mmrThreshold?: number | null): [number[], any[]];
declare abstract class BaseEmbedding {
    similarity(embedding1: number[], embedding2: number[], mode?: SimilarityType): number;
    abstract getTextEmbedding(text: string): Promise<number[]>;
    abstract getQueryEmbedding(query: string): Promise<number[]>;
}
declare enum OpenAIEmbeddingModelType {
    TEXT_EMBED_ADA_002 = "text-embedding-ada-002"
}
declare class OpenAIEmbedding extends BaseEmbedding {
    model: OpenAIEmbeddingModelType;
    apiKey?: string;
    maxRetries: number;
    timeout?: number;
    additionalSessionOptions?: Omit<Partial<ClientOptions$1>, "apiKey" | "maxRetries" | "timeout">;
    session: OpenAISession;
    constructor(init?: Partial<OpenAIEmbedding> & {
        azure?: AzureOpenAIConfig;
    });
    private getOpenAIEmbedding;
    getTextEmbedding(text: string): Promise<number[]>;
    getQueryEmbedding(query: string): Promise<number[]>;
}

declare class TextSplit {
    textChunk: string;
    numCharOverlap: number | undefined;
    constructor(textChunk: string, numCharOverlap?: number | undefined);
}
type SplitRep = {
    text: string;
    numTokens: number;
};
/**
 * Tokenizes sentences. Suitable for English and most European languages.
 * @param text
 * @returns
 */
declare const englishSentenceTokenizer: (text: string) => RegExpMatchArray | null;
/**
 * Tokenizes sentences. Suitable for Chinese, Japanese, and Korean.
 * @param text
 * @returns
 */
declare const cjkSentenceTokenizer: (text: string) => RegExpMatchArray | null;
declare const unixLineSeparator = "\n";
declare const windowsLineSeparator = "\r\n";
declare const unixParagraphSeparator: string;
declare const windowsParagraphSeparator: string;
/**
 * SentenceSplitter is our default text splitter that supports splitting into sentences, paragraphs, or fixed length chunks with overlap.
 *
 * One of the advantages of SentenceSplitter is that even in the fixed length chunks it will try to keep sentences together.
 */
declare class SentenceSplitter {
    private chunkSize;
    private chunkOverlap;
    private tokenizer;
    private tokenizerDecoder;
    private paragraphSeparator;
    private chunkingTokenizerFn;
    private splitLongSentences;
    constructor(options?: {
        chunkSize?: number;
        chunkOverlap?: number;
        tokenizer?: any;
        tokenizerDecoder?: any;
        paragraphSeparator?: string;
        chunkingTokenizerFn?: (text: string) => RegExpMatchArray | null;
        splitLongSentences?: boolean;
    });
    private getEffectiveChunkSize;
    getParagraphSplits(text: string, effectiveChunkSize?: number): string[];
    getSentenceSplits(text: string, effectiveChunkSize?: number): string[];
    /**
     * Splits sentences into chunks if necessary.
     *
     * This isn't great behavior because it can split down the middle of a
     * word or in non-English split down the middle of a Unicode codepoint
     * so the splitting is turned off by default. If you need it, please
     * set the splitLongSentences option to true.
     * @param sentenceSplits
     * @param effectiveChunkSize
     * @returns
     */
    private processSentenceSplits;
    combineTextSplits(newSentenceSplits: SplitRep[], effectiveChunkSize: number): TextSplit[];
    splitTextWithOverlaps(text: string, extraInfoStr?: string): TextSplit[];
    splitText(text: string, extraInfoStr?: string): string[];
}

/**
 * Splits the text of a document into smaller parts.
 * @param document - The document to split.
 * @param textSplitter - The text splitter to use.
 * @returns An array of text splits.
 */
declare function getTextSplitsFromDocument(document: Document, textSplitter: SentenceSplitter): string[];
/**
 * Generates an array of nodes from a document.
 * @param document - The document to generate nodes from.
 * @param textSplitter - The text splitter to use.
 * @param includeMetadata - Whether to include metadata in the nodes.
 * @param includePrevNextRel - Whether to include previous and next relationships in the nodes.
 * @returns An array of nodes.
 */
declare function getNodesFromDocument(document: Document, textSplitter: SentenceSplitter, includeMetadata?: boolean, includePrevNextRel?: boolean): TextNode[];
/**
 * A NodeParser generates TextNodes from Documents
 */
interface NodeParser {
    /**
     * Generates an array of nodes from an array of documents.
     * @param documents - The documents to generate nodes from.
     * @returns An array of nodes.
     */
    getNodesFromDocuments(documents: Document[]): TextNode[];
}
/**
 * SimpleNodeParser is the default NodeParser. It splits documents into TextNodes using a splitter, by default SentenceSplitter
 */
declare class SimpleNodeParser implements NodeParser {
    /**
     * The text splitter to use.
     */
    textSplitter: SentenceSplitter;
    /**
     * Whether to include metadata in the nodes.
     */
    includeMetadata: boolean;
    /**
     * Whether to include previous and next relationships in the nodes.
     */
    includePrevNextRel: boolean;
    constructor(init?: {
        textSplitter?: SentenceSplitter;
        includeMetadata?: boolean;
        includePrevNextRel?: boolean;
        chunkSize?: number;
        chunkOverlap?: number;
    });
    static fromDefaults(init?: {
        chunkSize?: number;
        chunkOverlap?: number;
        includeMetadata?: boolean;
        includePrevNextRel?: boolean;
    }): SimpleNodeParser;
    /**
     * Generate Node objects from documents
     * @param documents
     */
    getNodesFromDocuments(documents: Document[]): TextNode[];
}

/**
 * A collection of helper functions for working with prompts.
 */
declare class PromptHelper {
    contextWindow: number;
    numOutput: number;
    chunkOverlapRatio: number;
    chunkSizeLimit?: number;
    tokenizer: (text: string) => number[];
    separator: string;
    constructor(contextWindow?: number, numOutput?: number, chunkOverlapRatio?: number, chunkSizeLimit?: number, tokenizer?: (text: string) => number[], separator?: string);
    /**
     * Given a prompt, return the maximum size of the inputs to the prompt.
     * @param prompt
     * @returns
     */
    private getAvailableContextSize;
    /**
     * Find the maximum size of each chunk given a prompt.
     * @param prompt
     * @param numChunks
     * @param padding
     * @returns
     */
    private getAvailableChunkSize;
    /**
     * Creates a text splitter with the correct chunk sizes and overlaps given a prompt.
     * @param prompt
     * @param numChunks
     * @param padding
     * @returns
     */
    getTextSplitterGivenPrompt(prompt: SimplePrompt, numChunks?: number, padding?: number): SentenceSplitter;
    /**
     * Repack resplits the strings based on the optimal text splitter.
     * @param prompt
     * @param textChunks
     * @param padding
     * @returns
     */
    repack(prompt: SimplePrompt, textChunks: string[], padding?: number): string[];
}

/**
 * The ServiceContext is a collection of components that are used in different parts of the application.
 */
interface ServiceContext {
    llm: LLM;
    promptHelper: PromptHelper;
    embedModel: BaseEmbedding;
    nodeParser: NodeParser;
    callbackManager: CallbackManager;
}
interface ServiceContextOptions {
    llm?: LLM;
    promptHelper?: PromptHelper;
    embedModel?: BaseEmbedding;
    nodeParser?: NodeParser;
    callbackManager?: CallbackManager;
    chunkSize?: number;
    chunkOverlap?: number;
}
declare function serviceContextFromDefaults(options?: ServiceContextOptions): ServiceContext;
declare function serviceContextFromServiceContext(serviceContext: ServiceContext, options: ServiceContextOptions): {
    llm: LLM;
    promptHelper: PromptHelper;
    embedModel: BaseEmbedding;
    nodeParser: NodeParser;
    callbackManager: CallbackManager;
};

/**
 * Response modes of the response synthesizer
 */
declare enum ResponseMode {
    REFINE = "refine",
    COMPACT = "compact",
    TREE_SUMMARIZE = "tree_summarize",
    SIMPLE = "simple"
}
/**
 * A ResponseBuilder is used in a response synthesizer to generate a response from multiple response chunks.
 */
interface BaseResponseBuilder {
    /**
     * Get the response from a query and a list of text chunks.
     * @param query
     * @param textChunks
     * @param parentEvent
     * @param prevResponse
     */
    getResponse(query: string, textChunks: string[], parentEvent?: Event, prevResponse?: string): Promise<string>;
}
/**
 * A response builder that just concatenates responses.
 */
declare class SimpleResponseBuilder implements BaseResponseBuilder {
    llm: LLM;
    textQATemplate: SimplePrompt;
    constructor(serviceContext: ServiceContext);
    getResponse(query: string, textChunks: string[], parentEvent?: Event): Promise<string>;
}
/**
 * A response builder that uses the query to ask the LLM generate a better response using multiple text chunks.
 */
declare class Refine implements BaseResponseBuilder {
    serviceContext: ServiceContext;
    textQATemplate: SimplePrompt;
    refineTemplate: SimplePrompt;
    constructor(serviceContext: ServiceContext, textQATemplate?: SimplePrompt, refineTemplate?: SimplePrompt);
    getResponse(query: string, textChunks: string[], parentEvent?: Event, prevResponse?: string): Promise<string>;
    private giveResponseSingle;
    private refineResponseSingle;
}
/**
 * CompactAndRefine is a slight variation of Refine that first compacts the text chunks into the smallest possible number of chunks.
 */
declare class CompactAndRefine extends Refine {
    getResponse(query: string, textChunks: string[], parentEvent?: Event, prevResponse?: string): Promise<string>;
}
/**
 * TreeSummarize repacks the text chunks into the smallest possible number of chunks and then summarizes them, then recursively does so until there's one chunk left.
 */
declare class TreeSummarize implements BaseResponseBuilder {
    serviceContext: ServiceContext;
    constructor(serviceContext: ServiceContext);
    getResponse(query: string, textChunks: string[], parentEvent?: Event): Promise<string>;
}
declare function getResponseBuilder(serviceContext: ServiceContext, responseMode?: ResponseMode): BaseResponseBuilder;
/**
 * A ResponseSynthesizer is used to generate a response from a query and a list of nodes.
 */
declare class ResponseSynthesizer {
    responseBuilder: BaseResponseBuilder;
    serviceContext: ServiceContext;
    metadataMode: MetadataMode;
    constructor({ responseBuilder, serviceContext, metadataMode, }?: {
        responseBuilder?: BaseResponseBuilder;
        serviceContext?: ServiceContext;
        metadataMode?: MetadataMode;
    });
    synthesize(query: string, nodes: NodeWithScore[], parentEvent?: Event): Promise<Response>;
}

/**
 * Retrievers retrieve the nodes that most closely match our query in similarity.
 */
interface BaseRetriever {
    retrieve(query: string, parentEvent?: Event): Promise<NodeWithScore[]>;
    getServiceContext(): ServiceContext;
}

/**
 * A query engine is a question answerer that can use one or more steps.
 */
interface BaseQueryEngine {
    /**
     * Query the query engine and get a response.
     * @param query
     * @param parentEvent
     */
    query(query: string, parentEvent?: Event): Promise<Response>;
}
/**
 * A query engine that uses a retriever to query an index and then synthesizes the response.
 */
declare class RetrieverQueryEngine implements BaseQueryEngine {
    retriever: BaseRetriever;
    responseSynthesizer: ResponseSynthesizer;
    constructor(retriever: BaseRetriever, responseSynthesizer?: ResponseSynthesizer);
    query(query: string, parentEvent?: Event): Promise<Response>;
}
/**
 * SubQuestionQueryEngine decomposes a question into subquestions and then
 */
declare class SubQuestionQueryEngine implements BaseQueryEngine {
    responseSynthesizer: ResponseSynthesizer;
    questionGen: BaseQuestionGenerator;
    queryEngines: Record<string, BaseQueryEngine>;
    metadatas: ToolMetadata[];
    constructor(init: {
        questionGen: BaseQuestionGenerator;
        responseSynthesizer: ResponseSynthesizer;
        queryEngineTools: QueryEngineTool[];
    });
    static fromDefaults(init: {
        queryEngineTools: QueryEngineTool[];
        questionGen?: BaseQuestionGenerator;
        responseSynthesizer?: ResponseSynthesizer;
        serviceContext?: ServiceContext;
    }): SubQuestionQueryEngine;
    query(query: string): Promise<Response>;
    private querySubQ;
}

interface ToolMetadata {
    description: string;
    name: string;
}
/**
 * Simple Tool interface. Likely to change.
 */
interface BaseTool {
    metadata: ToolMetadata;
}
/**
 * A Tool that uses a QueryEngine.
 */
interface QueryEngineTool extends BaseTool {
    queryEngine: BaseQueryEngine;
}

/**
 * A SimplePrompt is a function that takes a dictionary of inputs and returns a string.
 * NOTE this is a different interface compared to LlamaIndex Python
 * NOTE 2: we default to empty string to make it easy to calculate prompt sizes
 */
type SimplePrompt = (input: Record<string, string>) => string;
declare const defaultTextQaPrompt: SimplePrompt;
declare const defaultSummaryPrompt: SimplePrompt;
declare const defaultRefinePrompt: SimplePrompt;
declare const defaultTreeSummarizePrompt: SimplePrompt;
declare const defaultChoiceSelectPrompt: SimplePrompt;
declare function buildToolsText(tools: ToolMetadata[]): string;
declare const defaultSubQuestionPrompt: SimplePrompt;
declare const defaultCondenseQuestionPrompt: SimplePrompt;
declare function messagesToHistoryStr(messages: ChatMessage[]): string;
declare const contextSystemPrompt: SimplePrompt;

/**
 * A ChatEngine is used to handle back and forth chats between the application and the LLM.
 */
interface ChatEngine {
    /**
     * Send message along with the class's current chat history to the LLM.
     * @param message
     * @param chatHistory optional chat history if you want to customize the chat history
     */
    chat(message: string, chatHistory?: ChatMessage[]): Promise<Response>;
    /**
     * Resets the chat history so that it's empty.
     */
    reset(): void;
}
/**
 * SimpleChatEngine is the simplest possible chat engine. Useful for using your own custom prompts.
 */
declare class SimpleChatEngine implements ChatEngine {
    chatHistory: ChatMessage[];
    llm: LLM;
    constructor(init?: Partial<SimpleChatEngine>);
    chat(message: string, chatHistory?: ChatMessage[]): Promise<Response>;
    reset(): void;
}
/**
 * CondenseQuestionChatEngine is used in conjunction with a Index (for example VectorStoreIndex).
 * It does two steps on taking a user's chat message: first, it condenses the chat message
 * with the previous chat history into a question with more context.
 * Then, it queries the underlying Index using the new question with context and returns
 * the response.
 * CondenseQuestionChatEngine performs well when the input is primarily questions about the
 * underlying data. It performs less well when the chat messages are not questions about the
 * data, or are very referential to previous context.
 */
declare class CondenseQuestionChatEngine implements ChatEngine {
    queryEngine: BaseQueryEngine;
    chatHistory: ChatMessage[];
    serviceContext: ServiceContext;
    condenseMessagePrompt: SimplePrompt;
    constructor(init: {
        queryEngine: BaseQueryEngine;
        chatHistory: ChatMessage[];
        serviceContext?: ServiceContext;
        condenseMessagePrompt?: SimplePrompt;
    });
    private condenseQuestion;
    chat(message: string, chatHistory?: ChatMessage[] | undefined): Promise<Response>;
    reset(): void;
}
/**
 * ContextChatEngine uses the Index to get the appropriate context for each query.
 * The context is stored in the system prompt, and the chat history is preserved,
 * ideally allowing the appropriate context to be surfaced for each query.
 */
declare class ContextChatEngine implements ChatEngine {
    retriever: BaseRetriever;
    chatModel: OpenAI;
    chatHistory: ChatMessage[];
    constructor(init: {
        retriever: BaseRetriever;
        chatModel?: OpenAI;
        chatHistory?: ChatMessage[];
    });
    chat(message: string, chatHistory?: ChatMessage[] | undefined): Promise<Response>;
    reset(): void;
}

declare const DEFAULT_CONTEXT_WINDOW = 3900;
declare const DEFAULT_NUM_OUTPUTS = 256;
declare const DEFAULT_CHUNK_SIZE = 1024;
declare const DEFAULT_CHUNK_OVERLAP = 20;
declare const DEFAULT_CHUNK_OVERLAP_RATIO = 0.1;
declare const DEFAULT_SIMILARITY_TOP_K = 2;
declare const DEFAULT_EMBEDDING_DIM = 1536;
declare const DEFAULT_PADDING = 5;

/**
 * Helper class singleton
 */
declare class GlobalsHelper {
    defaultTokenizer: {
        encode: (text: string) => number[];
        decode: (tokens: number[]) => string;
    } | null;
    tokenizer(): (text: string) => number[];
    tokenizerDecoder(): (tokens: number[]) => string;
    createEvent({ parentEvent, type, tags, }: {
        parentEvent?: Event;
        type: EventType;
        tags?: EventTag[];
    }): Event;
}
declare const globalsHelper: GlobalsHelper;

interface RefDocInfo {
    nodeIds: string[];
    extraInfo: Record<string, any>;
}
declare abstract class BaseDocumentStore {
    persist(persistPath?: string, fs?: GenericFileSystem): void;
    abstract docs(): Promise<Record<string, BaseNode>>;
    abstract addDocuments(docs: BaseNode[], allowUpdate: boolean): Promise<void>;
    abstract getDocument(docId: string, raiseError: boolean): Promise<BaseNode | undefined>;
    abstract deleteDocument(docId: string, raiseError: boolean): Promise<void>;
    abstract documentExists(docId: string): Promise<boolean>;
    abstract setDocumentHash(docId: string, docHash: string): void;
    abstract getDocumentHash(docId: string): Promise<string | undefined>;
    abstract getAllRefDocInfo(): Promise<Record<string, RefDocInfo> | undefined>;
    abstract getRefDocInfo(refDocId: string): Promise<RefDocInfo | undefined>;
    abstract deleteRefDoc(refDocId: string, raiseError: boolean): Promise<void>;
    getNodes(nodeIds: string[], raiseError?: boolean): Promise<BaseNode[]>;
    getNode(nodeId: string, raiseError?: boolean): Promise<BaseNode>;
    getNodeDict(nodeIdDict: {
        [index: number]: string;
    }): Promise<Record<number, BaseNode>>;
}

declare abstract class BaseIndexStore {
    abstract getIndexStructs(): Promise<IndexStruct[]>;
    abstract addIndexStruct(indexStruct: IndexStruct): Promise<void>;
    abstract deleteIndexStruct(key: string): Promise<void>;
    abstract getIndexStruct(structId?: string): Promise<IndexStruct | undefined>;
    persist(persistPath?: string, fs?: GenericFileSystem): Promise<void>;
}

interface StorageContext {
    docStore: BaseDocumentStore;
    indexStore: BaseIndexStore;
    vectorStore: VectorStore;
}
type BuilderParams = {
    docStore?: BaseDocumentStore;
    indexStore?: BaseIndexStore;
    vectorStore?: VectorStore;
    persistDir?: string;
    fs?: GenericFileSystem;
};
declare function storageContextFromDefaults({ docStore, indexStore, vectorStore, persistDir, fs, }: BuilderParams): Promise<StorageContext>;

/**
 * The underlying structure of each index.
 */
declare abstract class IndexStruct {
    indexId: string;
    summary?: string;
    constructor(indexId?: string, summary?: undefined);
    toJson(): Record<string, unknown>;
    getSummary(): string;
}
declare enum IndexStructType {
    SIMPLE_DICT = "simple_dict",
    LIST = "list"
}
declare class IndexDict extends IndexStruct {
    nodesDict: Record<string, BaseNode>;
    type: IndexStructType;
    getSummary(): string;
    addNode(node: BaseNode, textId?: string): void;
    toJson(): Record<string, unknown>;
    delete(nodeId: string): void;
}
declare function jsonToIndexStruct(json: any): IndexStruct;
declare class IndexList extends IndexStruct {
    nodes: string[];
    type: IndexStructType;
    addNode(node: BaseNode): void;
    toJson(): Record<string, unknown>;
}
interface BaseIndexInit<T> {
    serviceContext: ServiceContext;
    storageContext: StorageContext;
    docStore: BaseDocumentStore;
    vectorStore?: VectorStore;
    indexStore?: BaseIndexStore;
    indexStruct: T;
}
/**
 * Indexes are the data structure that we store our nodes and embeddings in so
 * they can be retrieved for our queries.
 */
declare abstract class BaseIndex<T> {
    serviceContext: ServiceContext;
    storageContext: StorageContext;
    docStore: BaseDocumentStore;
    vectorStore?: VectorStore;
    indexStore?: BaseIndexStore;
    indexStruct: T;
    constructor(init: BaseIndexInit<T>);
    /**
     * Create a new retriever from the index.
     * @param retrieverOptions
     */
    abstract asRetriever(options?: any): BaseRetriever;
    /**
     * Create a new query engine from the index. It will also create a retriever
     * and response synthezier if they are not provided.
     * @param options you can supply your own custom Retriever and ResponseSynthesizer
     */
    abstract asQueryEngine(options?: {
        retriever?: BaseRetriever;
        responseSynthesizer?: ResponseSynthesizer;
    }): BaseQueryEngine;
    /**
     * Insert a document into the index.
     * @param document
     */
    insert(document: Document): Promise<void>;
    abstract insertNodes(nodes: BaseNode[]): Promise<void>;
    abstract deleteRefDoc(refDocId: string, deleteFromDocStore?: boolean): Promise<void>;
}

declare enum ListRetrieverMode {
    DEFAULT = "default",
    LLM = "llm"
}
interface ListIndexOptions {
    nodes?: BaseNode[];
    indexStruct?: IndexList;
    indexId?: string;
    serviceContext?: ServiceContext;
    storageContext?: StorageContext;
}
/**
 * A ListIndex keeps nodes in a sequential list structure
 */
declare class ListIndex extends BaseIndex<IndexList> {
    constructor(init: BaseIndexInit<IndexList>);
    static init(options: ListIndexOptions): Promise<ListIndex>;
    static fromDocuments(documents: Document[], args?: {
        storageContext?: StorageContext;
        serviceContext?: ServiceContext;
    }): Promise<ListIndex>;
    asRetriever(options?: {
        mode: ListRetrieverMode;
    }): BaseRetriever;
    asQueryEngine(options?: {
        retriever?: BaseRetriever;
        responseSynthesizer?: ResponseSynthesizer;
    }): BaseQueryEngine;
    static buildIndexFromNodes(nodes: BaseNode[], docStore: BaseDocumentStore, indexStruct?: IndexList): Promise<IndexList>;
    insertNodes(nodes: BaseNode[]): Promise<void>;
    deleteRefDoc(refDocId: string, deleteFromDocStore?: boolean): Promise<void>;
    deleteNodes(nodeIds: string[], deleteFromDocStore: boolean): Promise<void>;
    getRefDocInfo(): Promise<Record<string, RefDocInfo>>;
}

type NodeFormatterFunction = (summaryNodes: BaseNode[]) => string;
type ChoiceSelectParseResult = {
    [docNumber: number]: number;
};
type ChoiceSelectParserFunction = (answer: string, numChoices: number, raiseErr?: boolean) => ChoiceSelectParseResult;

/**
 * Simple retriever for ListIndex that returns all nodes
 */
declare class ListIndexRetriever implements BaseRetriever {
    index: ListIndex;
    constructor(index: ListIndex);
    retrieve(query: string, parentEvent?: Event): Promise<NodeWithScore[]>;
    getServiceContext(): ServiceContext;
}
/**
 * LLM retriever for ListIndex.
 */
declare class ListIndexLLMRetriever implements BaseRetriever {
    index: ListIndex;
    choiceSelectPrompt: SimplePrompt;
    choiceBatchSize: number;
    formatNodeBatchFn: NodeFormatterFunction;
    parseChoiceSelectAnswerFn: ChoiceSelectParserFunction;
    serviceContext: ServiceContext;
    constructor(index: ListIndex, choiceSelectPrompt?: SimplePrompt, choiceBatchSize?: number, formatNodeBatchFn?: NodeFormatterFunction, parseChoiceSelectAnswerFn?: ChoiceSelectParserFunction, serviceContext?: ServiceContext);
    retrieve(query: string, parentEvent?: Event): Promise<NodeWithScore[]>;
    getServiceContext(): ServiceContext;
}

/**
 * VectorIndexRetriever retrieves nodes from a VectorIndex.
 */
declare class VectorIndexRetriever implements BaseRetriever {
    index: VectorStoreIndex;
    similarityTopK: number;
    private serviceContext;
    constructor({ index, similarityTopK, }: {
        index: VectorStoreIndex;
        similarityTopK?: number;
    });
    retrieve(query: string, parentEvent?: Event): Promise<NodeWithScore[]>;
    getServiceContext(): ServiceContext;
}

interface VectorIndexOptions {
    nodes?: BaseNode[];
    indexStruct?: IndexDict;
    indexId?: string;
    serviceContext?: ServiceContext;
    storageContext?: StorageContext;
}
/**
 * The VectorStoreIndex, an index that stores the nodes only according to their vector embedings.
 */
declare class VectorStoreIndex extends BaseIndex<IndexDict> {
    vectorStore: VectorStore;
    private constructor();
    /**
     * The async init function should be called after the constructor.
     * This is needed to handle persistence.
     * @param options
     * @returns
     */
    static init(options: VectorIndexOptions): Promise<VectorStoreIndex>;
    /**
     * Get the embeddings for nodes.
     * @param nodes
     * @param serviceContext
     * @param logProgress log progress to console (useful for debugging)
     * @returns
     */
    static getNodeEmbeddingResults(nodes: BaseNode[], serviceContext: ServiceContext, logProgress?: boolean): Promise<BaseNode[]>;
    /**
     * Get embeddings for nodes and place them into the index.
     * @param nodes
     * @param serviceContext
     * @param vectorStore
     * @returns
     */
    static buildIndexFromNodes(nodes: BaseNode[], serviceContext: ServiceContext, vectorStore: VectorStore, docStore: BaseDocumentStore, indexDict?: IndexDict): Promise<IndexDict>;
    /**
     * High level API: split documents, get embeddings, and build index.
     * @param documents
     * @param storageContext
     * @param serviceContext
     * @returns
     */
    static fromDocuments(documents: Document[], args?: {
        storageContext?: StorageContext;
        serviceContext?: ServiceContext;
    }): Promise<VectorStoreIndex>;
    asRetriever(options?: any): VectorIndexRetriever;
    asQueryEngine(options?: {
        retriever?: BaseRetriever;
        responseSynthesizer?: ResponseSynthesizer;
    }): BaseQueryEngine;
    insertNodes(nodes: BaseNode[]): Promise<void>;
    deleteRefDoc(refDocId: string, deleteFromDocStore?: boolean): Promise<void>;
}

/**
 * A reader takes imports data into Document objects.
 */
interface BaseReader {
    loadData(...args: any[]): Promise<Document[]>;
}

/**
 * Read the text of a PDF
 */
declare class PDFReader implements BaseReader {
    loadData(file: string, fs?: GenericFileSystem): Promise<Document[]>;
}

/**
 * papaparse-based csv parser
 * @class CSVReader
 * @implements BaseReader
 */
declare class PapaCSVReader implements BaseReader {
    private concatRows;
    private colJoiner;
    private rowJoiner;
    private papaConfig?;
    /**
     * Constructs a new instance of the class.
     * @param {boolean} [concatRows=true] - whether to concatenate all rows into one document.If set to False, a Document will be created for each row.True by default.
     * @param {string} [colJoiner=', '] - Separator to use for joining cols per row. Set to ", " by default.
     * @param {string} [rowJoiner='\n'] - Separator to use for joining each row.Only used when `concat_rows=True`.Set to "\n" by default.
     */
    constructor(concatRows?: boolean, colJoiner?: string, rowJoiner?: string, papaConfig?: ParseConfig);
    /**
     * Loads data from csv files
     * @param {string} file - The path to the file to load.
     * @param {GenericFileSystem} [fs=DEFAULT_FS] - The file system to use for reading the file.
     * @returns {Promise<Document[]>}
     */
    loadData(file: string, fs?: GenericFileSystem): Promise<Document[]>;
}

declare const DEFAULT_COLLECTION = "data";
declare const DEFAULT_PERSIST_DIR = "./storage";
declare const DEFAULT_INDEX_STORE_PERSIST_FILENAME = "index_store.json";
declare const DEFAULT_DOC_STORE_PERSIST_FILENAME = "doc_store.json";
declare const DEFAULT_VECTOR_STORE_PERSIST_FILENAME = "vector_store.json";
declare const DEFAULT_GRAPH_STORE_PERSIST_FILENAME = "graph_store.json";
declare const DEFAULT_NAMESPACE = "docstore";

type StoredValue = Record<string, any> | null;
declare abstract class BaseKVStore {
    abstract put(key: string, val: Record<string, any>, collection?: string): Promise<void>;
    abstract get(key: string, collection?: string): Promise<StoredValue>;
    abstract getAll(collection?: string): Promise<Record<string, StoredValue>>;
    abstract delete(key: string, collection?: string): Promise<boolean>;
}
declare abstract class BaseInMemoryKVStore extends BaseKVStore {
    abstract persist(persistPath: string, fs?: GenericFileSystem): void;
    static fromPersistPath(persistPath: string): BaseInMemoryKVStore;
}

declare class KVDocumentStore extends BaseDocumentStore {
    private kvstore;
    private nodeCollection;
    private refDocCollection;
    private metadataCollection;
    constructor(kvstore: BaseKVStore, namespace?: string);
    docs(): Promise<Record<string, BaseNode>>;
    addDocuments(docs: BaseNode[], allowUpdate?: boolean): Promise<void>;
    getDocument(docId: string, raiseError?: boolean): Promise<BaseNode | undefined>;
    getRefDocInfo(refDocId: string): Promise<RefDocInfo | undefined>;
    getAllRefDocInfo(): Promise<Record<string, RefDocInfo> | undefined>;
    refDocExists(refDocId: string): Promise<boolean>;
    documentExists(docId: string): Promise<boolean>;
    private removeRefDocNode;
    deleteDocument(docId: string, raiseError?: boolean, removeRefDocNode?: boolean): Promise<void>;
    deleteRefDoc(refDocId: string, raiseError?: boolean): Promise<void>;
    setDocumentHash(docId: string, docHash: string): Promise<void>;
    getDocumentHash(docId: string): Promise<string | undefined>;
}

type DataType = Record<string, Record<string, any>>;
declare class SimpleKVStore extends BaseKVStore {
    private data;
    private persistPath;
    private fs;
    constructor(data?: DataType);
    put(key: string, val: any, collection?: string): Promise<void>;
    get(key: string, collection?: string): Promise<any>;
    getAll(collection?: string): Promise<DataType>;
    delete(key: string, collection?: string): Promise<boolean>;
    persist(persistPath: string, fs?: GenericFileSystem): Promise<void>;
    static fromPersistPath(persistPath: string, fs?: GenericFileSystem): Promise<SimpleKVStore>;
    toDict(): DataType;
    static fromDict(saveDict: DataType): SimpleKVStore;
}

type SaveDict = Record<string, any>;
declare class SimpleDocumentStore extends KVDocumentStore {
    private kvStore;
    constructor(kvStore?: SimpleKVStore, namespace?: string);
    static fromPersistDir(persistDir?: string, namespace?: string, fsModule?: GenericFileSystem): Promise<SimpleDocumentStore>;
    static fromPersistPath(persistPath: string, namespace?: string, fs?: GenericFileSystem): Promise<SimpleDocumentStore>;
    persist(persistPath?: string, fs?: GenericFileSystem): Promise<void>;
    static fromDict(saveDict: SaveDict, namespace?: string): SimpleDocumentStore;
    toDict(): SaveDict;
}

declare class KVIndexStore extends BaseIndexStore {
    private _kvStore;
    private _collection;
    constructor(kvStore: BaseKVStore, namespace?: string);
    addIndexStruct(indexStruct: IndexStruct): Promise<void>;
    deleteIndexStruct(key: string): Promise<void>;
    getIndexStruct(structId?: string): Promise<IndexStruct | undefined>;
    getIndexStructs(): Promise<IndexStruct[]>;
}

declare class SimpleIndexStore extends KVIndexStore {
    private kvStore;
    constructor(kvStore?: BaseInMemoryKVStore);
    static fromPersistDir(persistDir?: string, fs?: GenericFileSystem): Promise<SimpleIndexStore>;
    static fromPersistPath(persistPath: string, fs?: GenericFileSystem): Promise<SimpleIndexStore>;
    persist(persistPath?: string, fs?: GenericFileSystem): Promise<void>;
    static fromDict(saveDict: DataType): SimpleIndexStore;
    toDict(): Record<string, unknown>;
}

declare class SimpleVectorStoreData {
    embeddingDict: Record<string, number[]>;
    textIdToRefDocId: Record<string, string>;
}
declare class SimpleVectorStore implements VectorStore {
    storesText: boolean;
    private data;
    private fs;
    private persistPath;
    constructor(data?: SimpleVectorStoreData, fs?: GenericFileSystem);
    static fromPersistDir(persistDir?: string, fs?: GenericFileSystem): Promise<SimpleVectorStore>;
    get client(): any;
    get(textId: string): Promise<number[]>;
    add(embeddingResults: BaseNode[]): Promise<string[]>;
    delete(refDocId: string): Promise<void>;
    query(query: VectorStoreQuery): Promise<VectorStoreQueryResult>;
    persist(persistPath?: string, fs?: GenericFileSystem): Promise<void>;
    static fromPersistPath(persistPath: string, fs?: GenericFileSystem): Promise<SimpleVectorStore>;
    static fromDict(saveDict: SimpleVectorStoreData): SimpleVectorStore;
    toDict(): SimpleVectorStoreData;
}

type MarkdownTuple = [string | null, string];
/**
 * Extract text from markdown files.
 * Returns dictionary with keys as headers and values as the text between headers.
 */
declare class MarkdownReader implements BaseReader {
    private _removeHyperlinks;
    private _removeImages;
    /**
     * @param {boolean} [removeHyperlinks=true] - Indicates whether hyperlinks should be removed.
     * @param {boolean} [removeImages=true] - Indicates whether images should be removed.
     */
    constructor(removeHyperlinks?: boolean, removeImages?: boolean);
    /**
     * Convert a markdown file to a dictionary.
     * The keys are the headers and the values are the text under each header.
     * @param {string} markdownText - The markdown text to convert.
     * @returns {Array<MarkdownTuple>} - An array of tuples, where each tuple contains a header (or null) and its corresponding text.
     */
    markdownToTups(markdownText: string): MarkdownTuple[];
    removeImages(content: string): string;
    removeHyperlinks(content: string): string;
    parseTups(content: string): MarkdownTuple[];
    loadData(file: string, fs?: GenericFileSystem): Promise<Document[]>;
}

/**
 * Read a .txt file
 */
declare class TextFileReader implements BaseReader {
    loadData(file: string, fs?: CompleteFileSystem): Promise<Document[]>;
}
type SimpleDirectoryReaderLoadDataProps = {
    directoryPath: string;
    fs?: CompleteFileSystem;
    defaultReader?: BaseReader | null;
    fileExtToReader?: Record<string, BaseReader>;
};
/**
 * Read all of the documents in a directory. Currently supports PDF and TXT files.
 */
declare class SimpleDirectoryReader implements BaseReader {
    loadData({ directoryPath, fs, defaultReader, fileExtToReader, }: SimpleDirectoryReaderLoadDataProps): Promise<Document[]>;
}

export { ALL_AVAILABLE_LLAMADEUCE_MODELS, ALL_AVAILABLE_OPENAI_MODELS, Anthropic, BaseEmbedding, BaseIndex, BaseIndexInit, BaseNode, BaseOutputParser, BaseQueryEngine, BaseQuestionGenerator, BaseReader, BaseRetriever, BaseTool, CallbackManager, ChatEngine, ChatMessage, ChatResponse, CompactAndRefine, CompleteFileSystem, CompletionResponse, CondenseQuestionChatEngine, ContextChatEngine, DEFAULT_CHUNK_OVERLAP, DEFAULT_CHUNK_OVERLAP_RATIO, DEFAULT_CHUNK_SIZE, DEFAULT_COLLECTION, DEFAULT_CONTEXT_WINDOW, DEFAULT_DOC_STORE_PERSIST_FILENAME, DEFAULT_EMBEDDING_DIM, DEFAULT_FS, DEFAULT_GRAPH_STORE_PERSIST_FILENAME, DEFAULT_INDEX_STORE_PERSIST_FILENAME, DEFAULT_NAMESPACE, DEFAULT_NUM_OUTPUTS, DEFAULT_PADDING, DEFAULT_PERSIST_DIR, DEFAULT_SIMILARITY_TOP_K, DEFAULT_VECTOR_STORE_PERSIST_FILENAME, DeuceChatStrategy, Document, Event, EventTag, EventType, ExactMatchFilter, GPT4_MODELS, GenericFileSystem, InMemoryFileSystem, IndexDict, IndexList, IndexNode, IndexStruct, IndexStructType, LLM, LLMQuestionGenerator, ListIndex, ListIndexLLMRetriever, ListIndexRetriever, ListRetrieverMode, LlamaDeuce, MarkdownReader, MessageType, MetadataFilters, MetadataInfo, MetadataMode, NodeParser, NodeRelationship, NodeWithScore, ObjectType, OpenAI, OpenAIEmbedding, PDFReader, PapaCSVReader, QueryEngineTool, Refine, RelatedNodeInfo, RelatedNodeType, Response, ResponseSynthesizer, RetrievalCallbackResponse, RetrieverQueryEngine, SentenceSplitter, ServiceContext, ServiceContextOptions, SimilarityType, SimpleChatEngine, SimpleDirectoryReader, SimpleDirectoryReaderLoadDataProps, SimpleDocumentStore, SimpleIndexStore, SimpleNodeParser, SimplePrompt, SimpleResponseBuilder, SimpleVectorStore, StorageContext, StreamCallbackResponse, StreamToken, StructuredOutput, SubQuestion, SubQuestionOutputParser, SubQuestionQueryEngine, TURBO_MODELS, TextFileReader, TextNode, ToolMetadata, TreeSummarize, VectorIndexRetriever, VectorStore, VectorStoreIndex, VectorStoreInfo, VectorStoreQuery, VectorStoreQueryMode, VectorStoreQueryResult, VectorStoreQuerySpec, WalkableFileSystem, buildToolsText, cjkSentenceTokenizer, contextSystemPrompt, defaultChoiceSelectPrompt, defaultCondenseQuestionPrompt, defaultRefinePrompt, defaultSubQuestionPrompt, defaultSummaryPrompt, defaultTextQaPrompt, defaultTreeSummarizePrompt, englishSentenceTokenizer, exists, getNodeFS, getNodesFromDocument, getResponseBuilder, getTextSplitsFromDocument, getTopKEmbeddings, getTopKEmbeddingsLearner, getTopKMMREmbeddings, globalsHelper, jsonToIndexStruct, jsonToNode, messagesToHistoryStr, serviceContextFromDefaults, serviceContextFromServiceContext, similarity, storageContextFromDefaults, unixLineSeparator, unixParagraphSeparator, walk, windowsLineSeparator, windowsParagraphSeparator };
